{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4c61979-6eb9-47d1-b86c-2996c035ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76dd0ca7-c43e-4e90-87b2-72dfcd1cabd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.ToTensor()\n",
    "train_set=datasets.MNIST(root=\"data\",train=True,transform=transform,target_transform=None,download=True)\n",
    "test_set=datasets.MNIST(root=\"data\",train=False,transform=transform,target_transform=None,download=True)\n",
    "\n",
    "\n",
    "train_loader=DataLoader(train_set,batch_size=64,shuffle=True)\n",
    "test_loader=DataLoader(test_set,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24e61124-7fe8-4b62-9832-258c10cd199a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1568, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)  # MNIST: 1 channel\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32*7*7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))    # 28x28x16\n",
    "        x = self.pool(x)             # 14x14x16\n",
    "        x = F.relu(self.conv2(x))    # 14x14x32\n",
    "        x = self.pool(x)             # 7x7x32\n",
    "        x = x.view(-1, 32*7*7)       # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ea00cbc-deef-43c1-8801-30bec4cebe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Train Loss: 0.2393, Train Acc: 0.9276, Val Loss: 0.0681, Val Acc: 0.9773\n",
      "Epoch [2/5], Train Loss: 0.0620, Train Acc: 0.9811, Val Loss: 0.0462, Val Acc: 0.9849\n",
      "Epoch [3/5], Train Loss: 0.0444, Train Acc: 0.9859, Val Loss: 0.0483, Val Acc: 0.9851\n",
      "Epoch [4/5], Train Loss: 0.0333, Train Acc: 0.9898, Val Loss: 0.0547, Val Acc: 0.9814\n",
      "Epoch [5/5], Train Loss: 0.0261, Train Acc: 0.9917, Val Loss: 0.0304, Val Acc: 0.9906\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Lists to store metrics for each epoch\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Training Phase ---\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update metrics for this batch\n",
    "        running_train_loss += loss.item()\n",
    "        total_train += labels.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate average loss and accuracy for the training epoch\n",
    "    epoch_train_loss = running_train_loss / len(train_loader)\n",
    "    epoch_train_accuracy = correct_train / total_train\n",
    "    \n",
    "    # Append to the lists\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    train_accuracies.append(epoch_train_accuracy)\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    # No gradient calculation is needed during validation\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass only\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Update metrics for this batch\n",
    "            running_val_loss += loss.item()\n",
    "            total_val += labels.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate average loss and accuracy for the validation epoch\n",
    "    epoch_val_loss = running_val_loss / len(test_loader)\n",
    "    epoch_val_accuracy = correct_val / total_val\n",
    "    \n",
    "    # Append to the lists\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    val_accuracies.append(epoch_val_accuracy)\n",
    "    \n",
    "    # Print the results for the current epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_accuracy:.4f}, \"\n",
    "          f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d6b58cf-fe63-4879-9edc-eedcc03ce227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 3, 3])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x200 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Take first conv layer\n",
    "filters = model.conv1.weight.data.cpu()\n",
    "\n",
    "print(filters.shape)  # e.g., (16, 1, 3, 3) for MNIST\n",
    "\n",
    "fig, axes = plt.subplots(1, 16, figsize=(16, 2))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(filters[i, 0, :, :], cmap='gray')  # first channel\n",
    "    ax.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7691bdf-2625-4853-93d3-5a01875710b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Pick one image from dataloader\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m images, labels = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mval_loader\u001b[49m))\n\u001b[32m      5\u001b[39m img = images[\u001b[32m0\u001b[39m].unsqueeze(\u001b[32m0\u001b[39m).to(device)  \u001b[38;5;66;03m# add batch dimension\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Forward pass manually\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'val_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pick one image from dataloader\n",
    "images, labels = next(iter(val_loader))\n",
    "img = images[0].unsqueeze(0).to(device)  # add batch dimension\n",
    "\n",
    "# Forward pass manually\n",
    "x = F.relu(model.conv1(img))  # first conv layer\n",
    "x_pool = model.pool(x)        # after pooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488d7a8-bd20-4198-b750-4b9145535ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
